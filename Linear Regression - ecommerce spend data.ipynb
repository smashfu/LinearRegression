{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Linear Regression on E-commerce Customer Data\n\nWe will try to fit a linear regression model on E-commerce Data and try to predict the Yearly amount spent by a customer."},{"metadata":{"trusted":true},"cell_type":"code","source":"# Importing required libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import learning_curve\nfrom sklearn import metrics\nimport warnings\nwarnings.filterwarnings('ignore')\n%matplotlib inline","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customers = pd.read_csv('../input/ecommerce-customers/Ecommerce Customers.csv')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"customers.info()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":" info() tells us that there are 8 columns and 500 rows . Let us peak into the data using head()"},{"metadata":{"trusted":true},"cell_type":"code","source":"customers.head()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Using pairplot to see if there is some sort of correlation among columns with respect to yearly amount spent."},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.pairplot(customers)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"From the pair plots, we can see that data distribution is quite normal, and that there is a clear correlation between length of membership and yearly amount spent.<br>\nLet us find out more using heatmap"},{"metadata":{"trusted":true},"cell_type":"code","source":"sns.heatmap(customers.corr(), linewidth=0.5, annot=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The above heatmap confirms the correlation between 'length of membership' and 'Yearly amount spent'. We can also see that there is good degree of correlation between 'Yearly amount spent' and the column 'Time on app'. Also lesser degree of correlation with 'Avg. Session length'"},{"metadata":{"trusted":true},"cell_type":"code","source":"x = customers[['Time on App', 'Length of Membership']]\ny = customers['Yearly Amount Spent']","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"For the time being let's skip 'Avg. Session Length' column since it has lesser correlation. We shall include it later and see if it yields considerably better results."},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 50)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Splitting dataset into train and test , giving 30% as test data and 70% as train data"},{"metadata":{"trusted":true},"cell_type":"code","source":"lm = LinearRegression()\nlm.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Function to Plot Learning curve\ndef plot_lc(estimator, x, y, train_sizes):\n    train_sizes, train_scores, test_scores = learning_curve(lm,x,y, train_sizes = train_sizes, cv = 5,\n    scoring = 'neg_mean_squared_error')\n    train_scores_mean = np.mean(-train_scores, axis=1)\n    train_scores_std = np.std(-train_scores, axis=1)\n    test_scores_mean = np.mean(-test_scores, axis=1)\n    test_scores_std = np.std(-test_scores, axis=1)\n\n    plt.style.use('seaborn')\n    plt.plot(train_sizes, train_scores_mean, label = 'Training error')\n    plt.plot(train_sizes, test_scores_mean, label = 'Validation error')\n    plt.ylabel('MSE', fontsize = 14)\n    plt.xlabel('Training set size', fontsize = 14)\n    plt.title('Learning curve', fontsize = 18, y = 1.03)\n    plt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Coeffs are Time on App : {0} , Length of Membership: {1}\".format(lm.coef_[0], lm.coef_[1]))\nprint(\"Intercept : \",lm.intercept_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = lm.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(y_test, result)\nplt.xlabel(\"Actual values\")\nplt.ylabel(\"Predicted values\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_lc(lm,x,y,np.linspace(5, len(x_train), 10, dtype='int'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Learning curve for the linear regression model shows small gap between training and validation error, meaning that variance should be reduced.  "},{"metadata":{"trusted":true},"cell_type":"code","source":"print('R2 score : ',metrics.r2_score(y_test, result))\nprint('Variance: ',metrics.explained_variance_score(y_test,result))\nprint('MSE: ', metrics.mean_squared_error(y_test,result))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The predicted values and actual values seem to be agreeing with each other and the R2 score is also ~ 0.88, which is seems good enough. But the MSE seems to be higher .\nHowever, Let us add the column 'Avg. Session length' this time and check results to see if there's any improvement (if R2 score increases and MSE decreases)."},{"metadata":{"trusted":true},"cell_type":"code","source":"x = customers[['Time on App', 'Length of Membership','Avg. Session Length']]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 50)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Splitting dataset into train and test , giving 30% as test data and 70% as train data"},{"metadata":{"trusted":true},"cell_type":"code","source":"lm.fit(x_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Coeffs are Time on App : {0} , Length of Membership: {1} , Avg. Session Length: {2}\".format(lm.coef_[0], lm.coef_[1], lm.coef_[2]))\nprint(\"Intercept : \",lm.intercept_)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"result = lm.predict(x_test)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.scatter(y_test, result)\nplt.xlabel(\"Actual values\")\nplt.ylabel(\"Predicted values\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"This time , the predicted vs actual values is giving a leaner graph, which is better. Lets look further into R2 score and MSE."},{"metadata":{"trusted":true},"cell_type":"code","source":"plot_lc(lm,x,y,np.linspace(5, len(x_train), 10, dtype='int'))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Learning curve for the linear regression model shows that the gap between training and validation error has reduced, meaning that variance is further reduced."},{"metadata":{"trusted":true},"cell_type":"code","source":"print('R2 score : ',metrics.r2_score(y_test, result))\nprint('Variance: ',metrics.explained_variance_score(y_test,result))\nprint('MSE ', metrics.mean_squared_error(y_test,result))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Addition of the column 'Avg. Session Length' has greatly improved the model for us with increased R2 score of 0.981 and reduced MSE of 118.68"}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"}},"nbformat":4,"nbformat_minor":1}